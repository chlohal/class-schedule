<a href="#" class="link-open" aria-expanded="true" onclick="hideCatalogData('28', '3', '95370', '', this, ''); return false;">
				IDCE 319 - Quantitative Methods and Statistics For Evaluators			</a>
						<br>
			<table class="td_dark">
				<tr>
					<td class="coursepadding">
							<div class="ajaxcourseindentfix social-media-ajax">
                                <div class='acalog-social-media-links'> </div>					<span class="print_link">[<a href="javascript:acalogPopup('preview_course.php?catoid=28&coid=95370&print', 'preview_course', 770, 530, 'yes')" class="acalog-highlight-ignore" alt="Text Version" title="Print Course (opens a new window)">Print Course (opens a new window)</a>]</span>
				</div>
<div><h3>IDCE 319 - Quantitative Methods and Statistics For Evaluators </h3>  <p><hr>Research and evaluation (or Program Monitoring and Evaluation, M&amp;E) spans a wide range of conceptualizations and definitions.  Evaluators utilize a wide range of research methods and ways of thinking about and applying research, as they design and conduct evaluations.</p>

<p>Research methods can be either quantitative, qualitative, or a mix of both (i.e. mixed-methods). Similarly, evaluation can be quantitative, qualitative, or mixed, and evaluations draw on these very same research methods and methodologies but they are often used by evaluators somewhat differently than researchers.</p>

<p>What is important is that the methods and design that evaluators choose to use need to be relevant and appropriate to the specific program that is being evaluated and these methods need to be understood and used with the same level of insight, understanding, and rigor that formal academic researchers might do when conducting their own academic research.  The nuances and differences between research and evaluation can be confusing at times.<br><br><strong>Anticipated Terms Offered:</strong> Various<br><br></p></div>		</td>
	</tr>
</table>
<br>
